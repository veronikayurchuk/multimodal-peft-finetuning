{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc859d9d",
   "metadata": {},
   "source": [
    "# Advanced PaliGemma Fine-tuning: Custom Metrics & Systematic Hyperparameter Optimization\n",
    "\n",
    "*Going beyond \"loss goes down = model works better\"*\n",
    "\n",
    "Most fine-tuning tutorials stop at the basics: load model, train, watch loss decrease, call it done. But here's what I've learned from taking models from prototype to production—the real work starts where most tutorials end.\n",
    "\n",
    "This notebook explores the evaluation and experimentation approaches that bridge the gap between research demos and systems you'd actually deploy. We'll dive deeper into the systematic analysis that helps you understand not just *if* your model is improving, but *how* and *why*.\n",
    "\n",
    "**The Challenge**: Standard training metrics tell you surprisingly little about real-world performance. I've seen models with beautiful loss curves fail catastrophically on edge cases, generate inconsistent outputs, or perform poorly on the specific criteria that actually matter for the use case.\n",
    "\n",
    "**Our Approach**: Instead of relying on default metrics and hoping for the best, we'll implement custom evaluation frameworks and run ablation study with experiments to better understand how different metrics correlate with downstream performance\n",
    "\n",
    "## What We'll Explore\n",
    "\n",
    "**📊 Custom Metrics for Real-World Performance**\n",
    "- Build task-specific evaluation metrics that actually correlate with production performance\n",
    "- Implement memory-efficient computation strategies to track complex metrics during training\n",
    "- Learn to identify quality issues early rather than after expensive training runs\n",
    "\n",
    "**🔬 Systematic Hyperparameter Analysis**\n",
    "- Design principled ablation studies that isolate the impact of individual configuration choices\n",
    "- Quantify the trade-offs between model size, capacity, training efficiency, and final performance\n",
    "- Understand when to adjust LoRA rank vs. alpha scaling vs. training duration for optimal results\n",
    "\n",
    "\n",
    "By the end, you'll have a comprehensive framework for evaluating multimodal models during training and the experimental methodology to make data-driven decisions about hyperparameter optimization—moving beyond trial-and-error to systematic improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4b7ae",
   "metadata": {},
   "source": [
    "> **📚 Prerequisites**: This is an advanced tutorial that builds on fundamental concepts. If you're new to PaliGemma fine-tuning or PEFT methods, I recommend starting with the simpler tutorial first: [**PaliGemma Fine-tuning with QLORA and PEFT**](peft_paligemma_im2json_qlora_SFT.ipynb)\n",
    ">\n",
    "> The basic tutorial covers essential concepts like model loading, data preparation, and standard training workflows that we'll extend here with custom metrics and systematic experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c6ab7",
   "metadata": {},
   "source": [
    "## Image-to-JSON Paligemma Fine-tuning with QLoRA using Advanced Metrics Tracking\n",
    "\n",
    "Fine-tuning PaliGemma-3B on receipt extraction with QLoRA, enhanced by custom evaluation metrics that go beyond standard loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7814be11",
   "metadata": {},
   "source": [
    "Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login as hf_login\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    PaliGemmaForConditionalGeneration,\n",
    "    PaliGemmaProcessor,\n",
    ")\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import wandb\n",
    "\n",
    "from metrics import JSONMetrics\n",
    "from helper import extract_json_from_llm_output\n",
    "\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5ea10",
   "metadata": {},
   "source": [
    "### Authentication Setup.\n",
    "\n",
    "Since, we will be running the code on a remote instance, we want to minimize interaction with console and login automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_authentication(env_path=None):\n",
    "    \"\"\"\n",
    "    Set up authentication for Hugging Face Hub and Weights & Biases.\n",
    "    \n",
    "    Args:\n",
    "        env_path (str, optional): Path to .env file. If None, uses the same directory as the script.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Status of authentication attempts for each service\n",
    "    \"\"\"\n",
    "    # Default to .env file in the same directory as the script\n",
    "    if env_path is None:\n",
    "        env_path = os.path.join(os.path.dirname(__file__), '.env')\n",
    "    \n",
    "    # Load environment variables\n",
    "    load_dotenv(env_path)\n",
    "    \n",
    "    auth_status = {}\n",
    "    \n",
    "    # Authenticate with Hugging Face\n",
    "    hf_token = os.getenv('HF_TOKEN')\n",
    "    if hf_token:\n",
    "        try:\n",
    "            hf_login(token=hf_token, add_to_git_credential=True)\n",
    "            auth_status['huggingface'] = 'success'\n",
    "            print(\"Successfully logged in to Hugging Face Hub\")\n",
    "        except Exception as e:\n",
    "            auth_status['huggingface'] = f'error: {str(e)}'\n",
    "            print(f\"Error logging in to Hugging Face Hub: {e}\")\n",
    "    else:\n",
    "        auth_status['huggingface'] = 'no_token'\n",
    "        print(\"HF_TOKEN not found in environment variables. You may need to log in manually.\")\n",
    "    \n",
    "    # Authenticate with Weights & Biases\n",
    "    wandb_api_key = os.getenv('WANDB_API_KEY')\n",
    "    if wandb_api_key:\n",
    "        try:\n",
    "            wandb.login(key=wandb_api_key, relogin=True)\n",
    "            auth_status['wandb'] = 'success'\n",
    "            print(\"Successfully logged in to Weights & Biases\")\n",
    "        except Exception as e:\n",
    "            auth_status['wandb'] = f'error: {str(e)}'\n",
    "            print(f\"Error logging in to Weights & Biases: {e}\")\n",
    "    else:\n",
    "        auth_status['wandb'] = 'no_token'\n",
    "        print(\"WANDB_API_KEY not found in environment variables. You'll be prompted to log in if needed.\")\n",
    "    \n",
    "    return auth_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5442c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up authentication for services\n",
    "auth_status = setup_authentication()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01295bb",
   "metadata": {},
   "source": [
    "### Setting some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "device = \"cuda\"\n",
    "model_id = \"google/paligemma-3b-pt-224\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99df1c8",
   "metadata": {},
   "source": [
    "### Loading CORD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761312ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with appropriate size based on environment\n",
    "cord_ds = load_dataset(\"naver-clova-ix/cord-v2\")\n",
    "cord_trains_ds = cord_ds[\"train\"]\n",
    "cord_validation_ds = cord_ds[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b0fd7",
   "metadata": {},
   "source": [
    "### Custom Collation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
    "def collate_fn(examples):\n",
    "        texts = [f\"<image> <bos> Extract JSON \" for example in examples]\n",
    "        images = [example[\"image\"].convert(\"RGB\") for example in examples]\n",
    "        labels = [str(json.loads(example['ground_truth'])['gt_parse']) for example in examples]\n",
    "\n",
    "        tokens = processor(\n",
    "            text=texts,\n",
    "            images=images,\n",
    "            suffix=labels,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",  # Pad all sequences to max_length\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH\n",
    "        )\n",
    "        tokens = tokens.to(torch.bfloat16).to(device)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24709e16",
   "metadata": {},
   "source": [
    "## Memory-Efficient Training Strategies\n",
    "### Quantization and LoRA Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae31ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure BitsAndBytes for 4-bit quantization (CUDA only)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,  # Enable double quantization\n",
    ")\n",
    "    \n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    lora_alpha=32,  # Alpha parameter for LoRA scaling\n",
    "    lora_dropout=0.05  # Add dropout for better regularization\n",
    ")\n",
    "\n",
    "## Loading the Model with Quantization and LoRA\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters() # trainable params: 11,298,816 || all params: 2,934,765,296 || trainable%: 0.3850\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4cea4",
   "metadata": {},
   "source": [
    "## Configuring Supervised Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c471df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SFTConfig(\n",
    "    # Model output configuration\n",
    "    output_dir=\"paligemma-imgtojson-0002\", # Directory to save checkpoints and repository ID for HuggingFace Hub\n",
    "    \n",
    "    # Training duration parameters\n",
    "    num_train_epochs=3,                  # 3 epochs balances training time and performance for this task\n",
    "                                         # Alternative: Fewer epochs (1-2) might underfit; more epochs (4+) risk overfitting\n",
    "                                         # especially with small datasets or when using powerful models like PaliGamma\n",
    "    \n",
    "    # Batch size configuration\n",
    "    per_device_train_batch_size=4,       # Optimal for specific GPU used during training\n",
    "    per_device_eval_batch_size=4,        # Matching train batch size ensures consistent evaluation\n",
    "    \n",
    "    # Gradient optimization\n",
    "    gradient_accumulation_steps=8,       # Simulates larger batch size (effective batch = 4*8 = 32) without extra memory\n",
    "    gradient_checkpointing=True,         # Trades computation for memory by not storing all activations\n",
    "    \n",
    "    # Optimizer settings\n",
    "    optim=\"adamw_torch_fused\",           # Fused implementation is faster on CUDA devices\n",
    "    learning_rate=2e-4,                  # 2e-4 is optimal based on QLoRA paper for fine-tuning\n",
    "                                         # Alternative: Lower (5e-5) for more stability but slower convergence\n",
    "    \n",
    "    # Precision settings\n",
    "    bf16=True,                           # BFloat16 offers better numerical stability than FP16 while saving memory\n",
    "    tf32=False,                          # TF32 precision disabled as it's not supported on P100\n",
    "    \n",
    "    # Learning rate schedule\n",
    "    lr_scheduler_type=\"cosine\",          # Cosine decay provides smooth learning rate reduction\n",
    "    max_grad_norm=0.3,                   # 0.3 prevents gradient explosion based on QLoRA paper\n",
    "    warmup_ratio=0.03,                   # 3% warmup helps stabilize early training\n",
    "    \n",
    "    # Advanced evaluation settings\n",
    "    evaluation_strategy=\"steps\",         # Evaluate at regular step intervals rather than epochs\n",
    "    eval_steps=5,                        # Evaluate every 5 steps for quick feedback on model performance\n",
    "    save_strategy=\"steps\",               # Save at regular step intervals\n",
    "    save_steps=10,                       # Save every 10 steps to balance checkpoint frequency and storage\n",
    "    logging_steps=5,                     # Log metrics every 5 steps for detailed training progress\n",
    "\n",
    "    # Early stopping (currently disabled)\n",
    "    # load_best_model_at_end=True,       # When enabled, loads the best model according to metric_for_best_model\n",
    "    metric_for_best_model=\"eval_loss\",   # Evaluation loss is a good general metric for model quality\n",
    "    greater_is_better=False,             # Loss function is decreasing, lower values are better\n",
    "\n",
    "    # Memory optimization\n",
    "    dataloader_pin_memory=False,         # Disabled to reduce memory pressure\n",
    "                                         # Alternative: True could speed up data transfer to GPU but uses more memory\n",
    "    dataloader_num_workers=0,            # Single-process data loading to avoid memory duplication\n",
    "    remove_unused_columns=True,          # Removes unused colums\n",
    "\n",
    "    # Experiment tracking\n",
    "    push_to_hub=True,                    # Automatically push model to Hugging Face Hub for sharing/deployment\n",
    "    report_to=\"wandb\" if os.getenv('WANDB_API_KEY') else \"none\", # Use W&B for experiment tracking if API key exists\n",
    "    \n",
    "    # SFT specific parameters\n",
    "    dataset_text_field=\"\", # need a dummy field for collator\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True}, # important for collator\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}, # use reentrant checkpointing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89256f53",
   "metadata": {},
   "source": [
    "## Introducing Custom Merics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3a18e",
   "metadata": {},
   "source": [
    "### Custom Metrics: Beyond Loss Functions\n",
    "\n",
    "Standard loss functions optimize for token-level accuracy, but for structured outputs like JSON, we need metrics that capture what actually matters in production:\n",
    "\n",
    "**The Production Reality Check**:\n",
    "- **JSON Validity**: A model with great loss might generate unparseable JSON \n",
    "- **Structural Consistency**: Fields might be missing, nested incorrectly, or have wrong data types\n",
    "- **Value Accuracy**: Even valid JSON can have incorrect extracted values\n",
    "- **Field Coverage**: Critical information might be systematically missed\n",
    "\n",
    "#### Our Multi-Dimensional Evaluation Framework\n",
    "\n",
    "We implement **seven complementary metrics** through a custom `JSONMetrics` class (defined in `metrics.py`):\n",
    "\n",
    "**📊 Core Quality Metrics**:\n",
    "- **Structure Similarity**: Jaccard similarity of JSON keys—measures if the model captures the expected schema\n",
    "- **Value Accuracy**: Exact match percentage for shared keys—the gold standard for extraction tasks\n",
    "- **Field F1 Score**: Balances precision/recall of field detection—critical for incomplete extractions\n",
    "\n",
    "**🔍 Robustness Metrics**:\n",
    "- **Value Similarity**: Fuzzy matching using BLEU scores and string similarity—handles minor OCR variations and semantic differences\n",
    "- **Edit Distance**: Normalized Levenshtein distance between JSON strings—quantifies how many edits are needed (lower is better)\n",
    "\n",
    "**📈 Coverage Metrics**:\n",
    "- **Field Precision**: Measures how many predicted fields are actually correct\n",
    "- **Field Recall**: Measures how many ground truth fields were successfully captured\n",
    "\n",
    "**🎯 Composite Score**: Weighted combination of all metrics provides a single quality indicator.\n",
    "\n",
    "By tracking these metrics during training, we can understand not just *if* our model is improving, but *how* different aspects of extraction quality evolve—enabling targeted hyperparameter adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ea571",
   "metadata": {},
   "source": [
    "## Implementing Custom Metrics in SFTTrainer\n",
    "\n",
    "The key to production-ready fine-tuning is tracking metrics that actually matter for your use case. Here's how we integrate our custom JSON evaluation metrics directly into the training loop.\n",
    "\n",
    "### Step 1: Understanding the Trainer Integration\n",
    "\n",
    "The `SFTTrainer` accepts two crucial arguments for custom evaluation:\n",
    "- **`compute_metrics`**: Function called during evaluation to calculate custom metrics\n",
    "- **`preprocess_logits_for_metrics`**: Memory optimization function to prevent OOM errors\n",
    "\n",
    "Let's implement both step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_string(text: str):\n",
    "    \"\"\"\n",
    "    Helper function to extract JSON from a string.\n",
    "    This matches the pattern used in extract_json_from_llm_output.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to parse the entire string as JSON first\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # If that fails, try to find JSON within the string\n",
    "        json_pattern = r'\\{.*\\}'\n",
    "        match = re.search(json_pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            try:\n",
    "                return json.loads(match.group())\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "def compute_metrics(eval_preds) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate custom JSON metrics during evaluation.\n",
    "    \n",
    "    This function is called by SFTTrainer during evaluation steps to compute\n",
    "    task-specific metrics beyond standard loss functions.\n",
    "    \n",
    "    Args:\n",
    "        eval_preds: Object containing predictions and labels\n",
    "            - predictions[0]: Predicted token indices (after preprocess_logits_for_metrics)\n",
    "            - label_ids: Ground truth token indices\n",
    "            \n",
    "    Returns:\n",
    "        dict: Aggregated metrics for logging to experiment tracker\n",
    "    \"\"\"\n",
    "    labels = eval_preds.label_ids\n",
    "    predictions = eval_preds.predictions[0]\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    json_metrics = JSONMetrics()\n",
    "    tokenizer = processor.tokenizer\n",
    "    \n",
    "    # Sample subset to prevent evaluation slowdown\n",
    "    batch_size = len(predictions)\n",
    "    sample_size = min(30, batch_size)  # Process max 30 examples per evaluation\n",
    "    sample_indices = np.random.choice(batch_size, sample_size, replace=False)\n",
    "\n",
    "    # Collect metrics for each example\n",
    "    metrics_lists = {\n",
    "        'structure_similarities': [],\n",
    "        'value_accuracies': [],\n",
    "        'field_f1_scores': [],\n",
    "        'field_recalls': [],\n",
    "        'field_precisions': [],    \n",
    "        'value_similarities': [],\n",
    "        'edit_distances': [],\n",
    "        'overall_scores': []\n",
    "    }\n",
    "    \n",
    "    valid_json_count = 0\n",
    "    \n",
    "    # Process each sampled example\n",
    "    for idx in sample_indices:\n",
    "        try:\n",
    "            # Handle potential shape mismatches\n",
    "            if idx >= len(labels):\n",
    "                continue\n",
    "                \n",
    "            # Get tokens and remove padding\n",
    "            pred_tokens = predictions[idx][predictions[idx] != -100]\n",
    "            label_tokens = labels[idx][labels[idx] != -100]\n",
    "            \n",
    "            # Decode to text\n",
    "            pred_text = tokenizer.decode(pred_tokens, skip_special_tokens=True)\n",
    "            label_text = tokenizer.decode(label_tokens, skip_special_tokens=True)\n",
    "            \n",
    "            # Extract JSON from both prediction and ground truth\n",
    "            pred_json = extract_json_from_llm_output(pred_text)\n",
    "            label_json = extract_json_from_string(label_text)\n",
    "            \n",
    "            # Only calculate metrics if both are valid JSON\n",
    "            if pred_json is not None and label_json is not None:\n",
    "                valid_json_count += 1\n",
    "                \n",
    "                # Calculate all metrics using our custom JSONMetrics class\n",
    "                result = json_metrics.calculate_overall_score(pred_json, label_json)\n",
    "                \n",
    "                # Collect each metric (using correct field names from metrics.py)\n",
    "                metrics_lists['structure_similarities'].append(result['structure_similarity'])\n",
    "                metrics_lists['value_accuracies'].append(result['value_accuracy'])\n",
    "                metrics_lists['field_f1_scores'].append(result['field_f1'])\n",
    "                metrics_lists['field_recalls'].append(result['field_recall'])\n",
    "                metrics_lists['field_precisions'].append(result['field_precision'])\n",
    "                metrics_lists['value_similarities'].append(result['value_similarity'])\n",
    "                metrics_lists['edit_distances'].append(result['edit_distance'])\n",
    "                metrics_lists['overall_scores'].append(result['overall_score'])\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing example {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate final aggregated metrics\n",
    "    final_metrics = {'json_validity': valid_json_count / sample_size if sample_size > 0 else 0.0}\n",
    "    \n",
    "    # Average all collected metrics\n",
    "    for metric_name, values in metrics_lists.items():\n",
    "        if values:  # Only if we have valid values\n",
    "            final_metrics[metric_name.rstrip('s')] = np.mean(values)  # Remove plural 's'\n",
    "        else:\n",
    "            final_metrics[metric_name.rstrip('s')] = 0.0\n",
    "    \n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ec098",
   "metadata": {},
   "source": [
    "### Step 2: Memory Optimization for Large Models\n",
    "\n",
    "When working with large models, storing full logits in memory can cause OOM errors. The `preprocess_logits_for_metrics` function solves this by converting logits to predictions immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    🚨 CRITICAL MEMORY OPTIMIZATION 🚨\n",
    "    \n",
    "    Convert raw logits to predicted token indices before storing in memory.\n",
    "    This prevents OOM errors when evaluating large models.\n",
    "    \n",
    "    Without this function, the trainer would store the full logits tensor\n",
    "    (shape: [batch_size, sequence_length, vocab_size]) which can be massive.\n",
    "    \n",
    "    Args:\n",
    "        logits (tuple): Model output logits - typically (logits_tensor,)\n",
    "        labels (torch.Tensor): Ground truth labels\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (predicted_token_indices, labels)\n",
    "    \"\"\"\n",
    "    # Convert logits to predicted token indices (much smaller memory footprint)\n",
    "    predictions = torch.argmax(logits[0], dim=-1)\n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd249d",
   "metadata": {},
   "source": [
    "### Step 3: Integrating Everything into SFTTrainer\n",
    "\n",
    "Now we combine everything by passing our custom functions to the trainer. This enables automatic metric calculation and logging during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SFTTrainer with custom metrics integration\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=cord_trains_ds,\n",
    "    eval_dataset=cord_validation_ds,\n",
    "    data_collator=collate_fn,\n",
    "    dataset_text_field=\"\",\n",
    "    peft_config=lora_config,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    \n",
    "    # 🎯 KEY ADDITIONS: Custom metrics integration\n",
    "    compute_metrics=compute_metrics,                              # Our custom evaluation function\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics, # Memory optimization\n",
    ")\n",
    "\n",
    "print(\"✅ SFTTrainer configured with custom JSON metrics!\")\n",
    "print(\"📊 Metrics tracked: JSON validity, structure similarity, value accuracy, field F1, value similarity, edit distance\")\n",
    "print(\"🚀 Ready for training with production-grade evaluation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366593e",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa7764",
   "metadata": {},
   "source": [
    "## Training Results: Custom Metrics in Action\n",
    "\n",
    "Here are the results from fine-tuning PaliGemma-3B on the image-to-JSON task using QLoRA, tracked through our custom evaluation framework in Weights & Biases.\n",
    "\n",
    "### What to Look For in These Charts\n",
    "\n",
    "**Training Progress Indicators**:\n",
    "- **Loss Convergence**: Standard training loss shows optimization progress\n",
    "- **Custom Metrics Trends**: Our JSON-specific metrics reveal quality improvements that loss alone can't capture\n",
    "- **Stability Patterns**: Look for smooth improvements vs. erratic fluctuations\n",
    "\n",
    "**Key Insights from Custom Metrics**:\n",
    "- **JSON Validity**: Track how often the model generates parseable JSON\n",
    "- **Structure Similarity**: Monitor if the model learns the expected schema structure\n",
    "- **Value Accuracy**: Watch exact match rates improve as training progresses\n",
    "- **Edit Distance**: Lower values indicate predictions closer to ground truth\n",
    "\n",
    "These metrics provide early signals about model quality that you won't get from loss curves alone—exactly what you need for production deployment decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa371e82",
   "metadata": {},
   "source": [
    "### Training Metrics Evolution\n",
    "\n",
    "![Train Charts from Weights & Biases](./wandb_charts/custom_metric_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a5955",
   "metadata": {},
   "source": [
    "### Evaluation Metrics Deep Dive\n",
    "\n",
    "![Eval Charts from Weights & Biases](./wandb_charts/custom_metric_eval_part1.png)\n",
    "![Eval Charts from Weights & Biases](./wandb_charts/custom_metric_eval_part2.png)\n",
    "\n",
    "**Analysis Highlights**:\n",
    "- **Multi-dimensional tracking** reveals different aspects of model improvement\n",
    "- **Real-time feedback** enables early detection of training issues\n",
    "- **Production-relevant metrics** correlate with actual deployment performance\n",
    "\n",
    "This comprehensive view demonstrates why custom metrics are essential for structured output tasks—they provide actionable insights that guide both training decisions and hyperparameter optimization in our upcoming ablation studies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb4fe4",
   "metadata": {},
   "source": [
    "## Ablation Study Review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc2b4e",
   "metadata": {},
   "source": [
    "### Theoretical Foundations of QLoRA: Mathematical Formulation\n",
    "\n",
    "#### 1. **Low-Rank Decomposition Mathematics**\n",
    "\n",
    "The core insight of LoRA is that the weight updates during fine-tuning have a low \"intrinsic rank\". For a pre-trained weight matrix W₀ ∈ ℝ^(d×k), the adapted weight becomes:\n",
    "\n",
    "```\n",
    "W = W₀ + ΔW = W₀ + BA\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **B ∈ ℝ^(d×r)** and **A ∈ ℝ^(r×k)** are low-rank matrices\n",
    "- **r << min(d,k)** is the rank bottleneck\n",
    "- **ΔW = BA** represents the adaptation with only **r(d+k)** parameters instead of **dk**\n",
    "\n",
    "#### 2. **Quantization Impact Analysis**\n",
    "\n",
    "QLoRA introduces 4-bit quantization with the NF4 (NormalFloat4) data type:\n",
    "\n",
    "**Memory Reduction**: \n",
    "- Base model: ~2.9B × 16 bits = ~5.8GB\n",
    "- Quantized: ~2.9B × 4 bits = ~1.45GB  \n",
    "- **Reduction**: 75% memory savings\n",
    "\n",
    "#### 3. **Scaling Law α/r Relationship**\n",
    "\n",
    "The scaling factor α controls adaptation strength:\n",
    "\n",
    "```\n",
    "ΔW = (α/r) × BA\n",
    "```\n",
    "\n",
    "**Key Insight**: As r increases, α should scale proportionally to maintain consistent adaptation strength. Our experiments will validate different α/r ratios to find optimal values for vision-language tasks.\n",
    "\n",
    "#### 4. **Multimodal Attention Mechanism**\n",
    "\n",
    "PaliGemma processes vision and language modalities through cross-attention.\n",
    "LoRA adapts the cross-modal attention weights while preserving the pre-trained vision-language alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedabe68",
   "metadata": {},
   "source": [
    "## Systematic Ablation Studies: Data-Driven Hyperparameter Optimization\n",
    "\n",
    "An ablation study systematically varies one hyperparameter at a time while keeping others constant—this isolates the true impact of each configuration choice rather than relying on intuition or random search.\n",
    "\n",
    "### Experimental Design & Metrics Selection\n",
    "\n",
    "**Tracking Strategy**: While our custom framework tracks seven comprehensive metrics, I'll focus on three key indicators that capture different dimensions of model quality:\n",
    "\n",
    "- **Edit Distance** (lower is better): Measures how many character-level edits are needed to transform predictions into ground truth—captures overall output quality\n",
    "- **Field F1 Score**: Balances precision and recall of field detection—critical for incomplete extractions in production\n",
    "- **Value Accuracy**: Percentage of exact matches for shared fields—the gold standard for extraction tasks\n",
    "\n",
    "**Why These Three**: Together, they provide a holistic view covering structural accuracy (F1), content precision (Value Accuracy), and overall similarity (Edit Distance). This combination reveals trade-offs that single metrics might miss.\n",
    "\n",
    "### Experimental Results\n",
    "\n",
    "Each table row represents a controlled experiment with Weights & Biases tracking for complete reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7718c147",
   "metadata": {},
   "source": [
    "### Experiment 1: LoRA Rank (r) Analysis\n",
    "The LoRA rank `r` controls the number of trainable parameters in the adaptation matrices. \n",
    "\n",
    "Impact of changing R:\n",
    "- Lower R (e.g. 8–32): fewer trainable parameters, lower memory usage → faster training, better for small tasks.\n",
    "- Higher R (≥64–256): more capacity, capturing complex patterns, but slower and risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eabc62",
   "metadata": {},
   "source": [
    "Effect of each rank on trainable parameters.\n",
    "\n",
    "| Rand (r) | All parameters | Trainable parameters   | trainable%   |\n",
    "| ---- | ------------- | --- | --- |\n",
    "| 4  | 2,929,115,888 | 5,649,408  | 0.1929  |\n",
    "| 8  | 2,929,115,888 | 11,298,816 | 0.3850   |\n",
    "| 16 | 2,929,115,888 | 22,597,632 | 0.7670  | \n",
    "| 32 | 2,929,115,888 | 45,195,264 | 1.5224  |\n",
    "| 64 | 2,929,115,888 | 90,390,528 | 2.9992  |\n",
    "| 128 | 2,929,115,888 | 180,781,056 | 5.8237  |\n",
    "\n",
    "As the table illustrates, the number of trainable parameters scales linearly with the rank `r`. This has direct implications for the trade-off between model capacity and computational cost:\n",
    "- **Low Ranks (4-16)**: Keep the model lightweight and fast to train, making them ideal for initial experiments or tasks where minimal adaptation is needed. However, they might lack the capacity to capture complex details.\n",
    "- **Medium Ranks (32-64)**: Offer a balance between performance and computational cost. Our experiments show `r=32` is a sweet spot, providing significant performance gains without excessive overhead.\n",
    "- **High Ranks (128+)**: Provide maximum capacity but come with a higher risk of overfitting, longer training times, and diminishing returns on performance for many tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134266fa",
   "metadata": {},
   "source": [
    "For the first experiment, we will run a set of runs with different Rank (r) value, fixing lora_alpha = 2*r, this is to have a consistant weigths adaptation strenght. \n",
    "The goal is to find the lowest rank that achieves satisfactory performance.\n",
    "\n",
    "Here is a table with the results:\n",
    "| Config     |Experiment name| R   | α   | Dropout | LR   | Edit Distance | Field F1 Score | Value Accuracy | Value Sim\n",
    "| ---------- | ------------- | --- | --- | ------- | ----  | ----- | ----- | ---------- | ------- |\n",
    "| R ablation   | paligemma-img2json-0000 | 8 | 16  | 0.05    | 2e‑4  | 0.1407  | 0.8244 | 75.82 | 88.39\n",
    "| R ablation | paligemma-img2json-0013 | 16 | 32  | 0.05    | 2e‑4  | 0.1116 | 0.8646 | 80.33 | 90.52\n",
    "| Baseline  | paligemma-img2json-0009 | 32 | 64  | 0.05    | 2e‑4  | 0.085  | 0.883 | 81.9 | 93.65\n",
    "\n",
    "\n",
    "The charts below visualize the performance of each run during training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3451aac",
   "metadata": {},
   "source": [
    "#### Training Performance Comparison\n",
    "\n",
    "![Rank Ablation - Training Metrics](./wandb_charts/r_ablation_train.png)\n",
    "\n",
    "#### Evaluation Performance Comparison\n",
    "_(For brevity, some metrics are omitted from this report)_\n",
    "![Rank Ablation - Evaluation Metrics](./wandb_charts/r_ablation_eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c3d31",
   "metadata": {},
   "source": [
    "### Analysis & Key Findings\n",
    "\n",
    "- **Clear Correlation Between Rank and Performance**: The evaluation charts demonstrate a strong, positive correlation between LoRA rank and model performance. The `r=32` run (grey line) consistently achieves the best scores across all key metrics, including the lowest (best) `eval/edit_distance` and the highest `eval/value_accuracy` and `eval/field_f1_score`.\n",
    "\n",
    "- **Loss Curves Corroborate Metric Trends**: This observation is supported by the loss curves. Both `train/loss` and `eval/loss` are lowest for the `r=32` run, indicating that the model with greater capacity learned the task more effectively and generalized better to the validation set.\n",
    "\n",
    "- **Performance vs. Cost Trade-off**: While `r=32` has ~4x the trainable parameters of `r=8`, the performance gains are substantial. The improvement in **Value Accuracy** from 75.8% to 81.9% and the nearly 40% reduction in **Edit Distance** (from 0.1407 to 0.085) justify the increased computational cost for a production-oriented task where accuracy is critical.\n",
    "\n",
    "- **Conclusion**: For this image-to-JSON task, a rank of at least 32 is beneficial. The conventional wisdom that performance is \"largely independent of R\" may not hold for complex, structured data extraction tasks, or perhaps applies at ranks beyond 32 where we might see diminishing returns. This experiment underscores the necessity of empirical validation over relying on general heuristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494fd927",
   "metadata": {},
   "source": [
    "### Experiment 2: LoRA Alpha (α) Analysis\n",
    "The LoRA alpha (`α`) parameter acts as a scaling factor for the learned weight updates. The final update `ΔW` is scaled by `α/r`. This means `α` controls the magnitude of the adaptation.\n",
    "\n",
    "**Impact of changing α**:\n",
    "- A higher `α` gives more weight to the LoRA adaptation, allowing for more significant changes to the base model's behavior.\n",
    "- A lower `α` results in a more subtle adaptation.\n",
    "- A common heuristic is to set `α` to be twice the rank (`α = 2r`) or equal the rank (`α = r`), but the optimal ratio depends on the task and how much the base model needs to be adapted.\n",
    "\n",
    "For this experiment, we fix the rank `r=32` and compare `α=32` (i.e., `α=r`) against `α=64` (i.e., `α=2r`) to test this heuristic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341aca6",
   "metadata": {},
   "source": [
    "Here are the results comparing an alpha value equal to the rank versus double the rank:\n",
    "\n",
    "| Config     |Experiment name| R   | α   | Dropout | LR   | Edit Distance | Field F1 Score | Value Accuracy |\n",
    "| ---------- | ------------- | --- | --- | ------- | ----  | ----- | ----- | ---------- |\n",
    "| α = r   | paligemma-img2json-0008 | 32  | 32  | 0.05    | 2e‑4  | 0.1027 | 0.8672 | 77.49 |\n",
    "| α = 2r | paligemma-img2json-0009 | 32 | 64  | 0.05    | 2e‑4  | 0.085  | 0.883 | 81.9       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ade85a",
   "metadata": {},
   "source": [
    "#### Training Performance Comparison\n",
    "\n",
    "![Alpha Ablation - Training Metrics](./wandb_charts/alpha_ablation2_train.png)\n",
    "\n",
    "#### Evaluation Performance Comparison\n",
    "\n",
    "![Alpha Ablation - Evaluation Metrics](./wandb_charts/alpha_ablation2_eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93203f",
   "metadata": {},
   "source": [
    "### Analysis & Key Findings\n",
    "\n",
    "- **Higher Alpha Drives Performance**: The evaluation charts clearly show that `α=64` (grey line, `paligemma-img2json-0009`) significantly outperforms `α=32` (maroon line, `paligemma-img2json-0008`) across all key metrics. The model with stronger adaptation achieves lower (better) `eval/edit_distance` and higher scores for `eval/value_accuracy`, `eval/field_f1_score`, and `eval/structure_similarity`.\n",
    "\n",
    "- **Loss Curves Confirm Better Learning**: This trend is mirrored in the loss curves. The `α=64` run achieves a lower loss on both the training and evaluation sets, indicating that it learned more effectively and generalized better.\n",
    "\n",
    "- **Validating the `α = 2r` Heuristic**: The results strongly support the `α = 2r` heuristic for this task. Doubling alpha from 32 to 64 led to a substantial performance boost: **Value Accuracy** increased from 77.5% to 81.9%, and **Edit Distance** dropped by over 17% (from 0.1027 to 0.085). This indicates the base model required a more significant adaptation than an `α=r` setting could provide.\n",
    "\n",
    "- **Conclusion**: For this image-to-JSON task, a larger alpha relative to the rank is crucial. The base model needs considerable fine-tuning to handle structured data extraction, and a higher alpha provides the necessary scaling for the LoRA updates to be effective. The `α = 2r` rule of thumb proves to be a very effective starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7ad00",
   "metadata": {},
   "source": [
    "### Experiment 3: Dropout Analysis\n",
    "\n",
    "Dropout is a regularization technique used to prevent overfitting by randomly setting a fraction of neuron activations to zero during training. This forces the model to learn more robust features that are not dependent on any single neuron.\n",
    "\n",
    "**Impact of changing Dropout**:\n",
    "- **Higher Dropout**: Increases regularization, which can help prevent overfitting on larger models or with longer training, but may lead to underfitting if set too high.\n",
    "- **Lower/Zero Dropout**: Reduces or removes regularization. The original QLoRA paper noted that dropout was often unnecessary for very large models but could be beneficial for smaller ones (e.g., 7B parameter models).\n",
    "\n",
    "**Experimental Setup & Findings**:\n",
    "To assess its impact, I conducted experiments with `lora_dropout` set to `0.05` and `0.0`, keeping the previously determined optimal `r=32` and `α=64`. The results showed no significant difference in performance across our key metrics between the two configurations.\n",
    "\n",
    "**Conclusion**:\n",
    "Given that there were no clear signs of overfitting with a dropout of `0.05`, and no performance degradation compared to `0.0`, I chose to retain `lora_dropout=0.05` for all other experiments. This serves as a minor, low-cost safeguard against potential overfitting without negatively impacting the model's learning capacity on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81a8ab",
   "metadata": {},
   "source": [
    "### Experiment 4: Learning Rate Analysis\n",
    "\n",
    "The learning rate is controlling the step size the optimizer takes during weight updates. A learning rate scheduler, like the cosine scheduler used here (see visualized below), dynamically adjusts this rate during training to balance fast initial progress with stable convergence later on.\n",
    "\n",
    "**Impact of changing Learning Rate**:\n",
    "- **Higher Learning Rate**: Allows for faster training and can help escape local minima, but risks overshooting the optimal weights and becoming unstable.\n",
    "- **Lower Learning Rate**: Leads to more stable, predictable convergence but can be extremely slow and has a higher risk of getting stuck in suboptimal local minima.\n",
    "\n",
    "**Experimental Setup & Findings**:\n",
    "This experiment compares the recommended QLoRA learning rate of `2e-4` against a much smaller rate of `2e-5`. The goal is to demonstrate the dramatic impact of learning rate on training speed and final performance.\n",
    "\n",
    "#### Training Performance Comparison\n",
    "The `train/learning_rate` chart clearly shows the two different schedules. The `train/loss` chart shows the higher learning rate leads to much faster convergence.\n",
    "\n",
    "![Train Charts from Weights & Biases](./wandb_charts/learning_rate_train.png)\n",
    "\n",
    "#### Evaluation Performance Comparison\n",
    "The evaluation metrics confirm the training trends, with the higher learning rate achieving significantly better results.\n",
    "\n",
    "![Validation Charts from Weights & Biases](./wandb_charts/learning_rate_eval.png)\n",
    "\n",
    "### Analysis & Key Findings\n",
    "\n",
    "- **Learning Rate Dominates Performance**: The difference is stark. The higher learning rate (`2e-4`, purple line) vastly outperforms the lower rate across every single metric. Its `eval/loss` plummets, while the `eval/loss` for the lower rate barely decreases.\n",
    "\n",
    "- **Validation of QLoRA's Recommendation**: This experiment strongly validates the `2e-4` learning rate recommended in the QLoRA paper as an effective starting point. While further tuning might yield marginal gains, a significantly lower rate is clearly detrimental for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd2ffc",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This notebook demonstrated a comprehensive, production-oriented approach to fine-tuning a multimodal model for a structured data extraction task. By moving beyond simple loss monitoring and implementing a framework of custom, task-relevant metrics, we gained deep insights into model behavior and were able to make data-driven decisions.\n",
    "\n",
    "**Key Achievements**:\n",
    "1.  **Custom Metrics Framework**: We successfully integrated seven distinct metrics to evaluate JSON quality, structure, and value accuracy directly within the training loop. This provided a multi-dimensional view of performance that loss alone could not capture.\n",
    "2.  **Systematic Hyperparameter Optimization**: Through a series of controlled ablation studies, we systematically isolated the impact of key QLoRA hyperparameters. This data-driven process allowed us to move beyond heuristics and identify an optimal configuration for our specific task.\n",
    "\n",
    "**Optimal Configuration Found**:\n",
    "Our experiments converged on the following configuration as the most effective for this image-to-JSON task:\n",
    "- **LoRA Rank (`r`)**: 32\n",
    "- **LoRA Alpha (`α`)**: 64 (following the `α = 2r` ratio)\n",
    "- **Learning Rate**: `2e-4`\n",
    "- **Dropout**: `0.05`\n",
    "\n",
    "**Why This Matters**:\n",
    "The methodology presented here—combining custom evaluation with systematic experimentation—provides a robust and reproducible blueprint for fine-tuning models for specialized, real-world applications. It bridges the gap between academic research and production deployment by establishing a clear, evidence-based path to achieving optimal performance, ensuring that the final model is not just trained, but truly effective at its intended task.\n",
    "\n",
    "The next logical step is to take our optimized model and deploy it to a production-ready environment. Stay tuned for a future guide on serving this model efficiently at scale!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
